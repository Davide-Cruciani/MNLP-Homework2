{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dabd59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-generativeai\n",
    "# pip install rouge\n",
    "\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e8a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.environ['GEMINI_KEY'])\n",
    "DIRECTORY_PATH = os.environ['DATA_PATH']\n",
    "GEMINI_VERSION = \"gemini-1.5-flash\"\n",
    "\n",
    "cleaned_fn = \"cleaned.json\"\n",
    "ocred_fn = \"original_ocr.json\"\n",
    "\n",
    "\n",
    "datasetRaw = {}\n",
    "\n",
    "for file_name in [ocred_fn, cleaned_fn]:\n",
    "    if file_name not in os.listdir(DIRECTORY_PATH):\n",
    "        print(f\"ERROR 404 ! File {file_name} not Found...\")\n",
    "\n",
    "    file_path = os.path.join(DIRECTORY_PATH, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        datasetRaw[file_name.split('.')[0]] = json.load(file)\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3c0ad",
   "metadata": {},
   "source": [
    "### Output evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11dd40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.environ['OUTPUT_PATH']\n",
    "\n",
    "modes = [\n",
    "    {\n",
    "        \"name\":\"lama\",\n",
    "        \"folder\":\"Llama\"\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"minerva\",\n",
    "        \"folder\":\"Minerva\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9960e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_wrapper(segment_ocred, segment_clean):\n",
    "    return f\"\"\"\n",
    "        ### Task: Il primo testo è una versione del secondo estratto con oc-Red, ed è stata processata per ridurre gli errori, valuta con un punteggio tra 1 e 100 tenendo conto di correttezza, comprensibilità e somiglianza\n",
    "        ### Testo da valutare: {segment_ocred}.\n",
    "        ### Testo di confronto: {segment_clean}.\n",
    "        ### Requisiti:\n",
    "            - Scrivi il risultato in formato <criterio>:<punteggio>.\n",
    "            - Non usare altri numeri interi o fai altri commenti\n",
    "        ### Risultato:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515a3bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'lama': {'rouge-1': {'r': 0.9018096388956656, 'p': 0.8842998508666347, 'f': 0.8929096945437028}, 'rouge-2': {'r': 0.8611956693983525, 'p': 0.846038729355542, 'f': 0.853540266107022}, 'rouge-l': {'r': 0.9018096388956656, 'p': 0.8842998508666347, 'f': 0.8929096945437028}}, 'minerva': {'rouge-1': {'r': 0.8887436194479311, 'p': 0.8804857763436278, 'f': 0.8840809294354984}, 'rouge-2': {'r': 0.8440152974684236, 'p': 0.8457810368278075, 'f': 0.8442805294840483}, 'rouge-l': {'r': 0.8887436194479311, 'p': 0.8804857763436278, 'f': 0.8840809294354984}}}\n",
      "{'lama': {'rouge-1': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}, 'rouge-2': {'r': 0.8099428484682072, 'p': 0.7656059883750874, 'f': 0.7871362843543889}, 'rouge-l': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}}, 'minerva': {'rouge-1': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}, 'rouge-2': {'r': 0.8099428484682072, 'p': 0.7656059883750874, 'f': 0.7871362843543889}, 'rouge-l': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}}}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "baseline = {}\n",
    "gemini_eval = {}\n",
    "for mode in modes:\n",
    "    model_scorer = Rouge()\n",
    "    model_outputs = os.path.join(OUTPUT_PATH, mode['folder'])\n",
    "    gemini = genai.GenerativeModel(model_name=GEMINI_VERSION)\n",
    "    corrected_chapters = []\n",
    "    baseline_chapters = []\n",
    "    reference_chapters = []\n",
    "    gemini_eval[mode['name']] = []\n",
    "    for n, chapter in enumerate(os.listdir(model_outputs)):\n",
    "        complete_chapter = \"\"\n",
    "        with open(os.path.join(model_outputs, chapter), mode='r', encoding='utf-8') as file:\n",
    "            try:\n",
    "                chapter_object = json.load(file)\n",
    "            except Exception as e:\n",
    "                print(e, f\"while trying to read {mode['folder']}-{chapter}\")\n",
    "                continue\n",
    "            for line in chapter_object:\n",
    "                complete_chapter += (\"\\n\"+line['output'])\n",
    "            file.close()\n",
    "        corrected_chapters.append(complete_chapter)\n",
    "        reference_chapters.append(datasetRaw['cleaned'][f'{n+1}'])\n",
    "        baseline_chapters.append(datasetRaw['original_ocr'][f'{n+1}'])\n",
    "        evaluation = gemini.generate_content(segment_wrapper(complete_chapter, datasetRaw['cleaned'][f'{n+1}']))\n",
    "        gemini_eval[mode['name']].append(evaluation.text)\n",
    "    results[mode['name']] = model_scorer.get_scores(corrected_chapters,reference_chapters, avg=True)\n",
    "    baseline[mode['name']] = model_scorer.get_scores(baseline_chapters, reference_chapters, avg=True)\n",
    "    \n",
    "print(f\"{'-'*20}\")\n",
    "print(results)\n",
    "print(baseline)\n",
    "print(f\"{'-'*20}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0be417",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_res = pd.DataFrame(results['lama'])\n",
    "llama_base = pd.DataFrame(baseline['lama'])\n",
    "minerva_res = pd.DataFrame(results['minerva'])\n",
    "minerva_base = pd.DataFrame(baseline['minerva'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e25a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rouge-1   rouge-2  rouge-l\n",
      "r  0.90181  0.861196  0.90181\n",
      "p  0.88430  0.846039  0.88430\n",
      "f  0.89291  0.853540  0.89291\n",
      "    rouge-1   rouge-2   rouge-l\n",
      "r  0.866203  0.809943  0.866203\n",
      "p  0.799548  0.765606  0.799548\n",
      "f  0.831489  0.787136  0.831489\n",
      "    rouge-1   rouge-2   rouge-l\n",
      "r  0.888744  0.844015  0.888744\n",
      "p  0.880486  0.845781  0.880486\n",
      "f  0.884081  0.844281  0.884081\n",
      "    rouge-1   rouge-2   rouge-l\n",
      "r  0.866203  0.809943  0.866203\n",
      "p  0.799548  0.765606  0.799548\n",
      "f  0.831489  0.787136  0.831489\n"
     ]
    }
   ],
   "source": [
    "print(llama_res)\n",
    "print(llama_base)\n",
    "print(minerva_res)\n",
    "print(minerva_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fadadefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "2 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "3 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "4 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "5 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "6 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "7 Correttezza:85\n",
      "Comprensibilità:90\n",
      "Somiglianza:95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, content in enumerate(gemini_eval['lama']):\n",
    "    print(i+1, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c91cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Correttezza:85\n",
      "Comprensibilità:90\n",
      "Somiglianza:95\n",
      "\n",
      "2 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "3 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "4 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "5 Correttezza:90\n",
      "Comprensibilità:95\n",
      "Somiglianza:98\n",
      "\n",
      "6 Correttezza:85\n",
      "Comprensibilità:90\n",
      "Somiglianza:95\n",
      "\n",
      "7 Correttezza:85\n",
      "Comprensibilità:90\n",
      "Somiglianza:95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, content in enumerate(gemini_eval['minerva']):\n",
    "    print(i+1, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c30d43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(eval_list:list)-> list:\n",
    "    res = []\n",
    "    for n, sentence in enumerate(eval_list):\n",
    "        scores = sentence.strip().split('\\n')\n",
    "        entry = {}\n",
    "        for s in scores:\n",
    "            s = s.split(\":\")\n",
    "            entry[f\"{s[0]}\"] = int(s[1])/100\n",
    "        entry[\"id\"] = n+1\n",
    "        res.append(entry)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "287e2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "minerva_data = pd.DataFrame(converter(gemini_eval['minerva']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "970ad4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lama_data = pd.DataFrame(converter(gemini_eval['lama']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8afac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d4c4d9dd-560c-4692-b8dd-337532e609b6",
       "rows": [
        [
         "Correttezza",
         "0.8785714285714284"
        ],
        [
         "Comprensibilità",
         "0.9285714285714287"
        ],
        [
         "Somiglianza",
         "0.9671428571428572"
        ],
        [
         "id",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "Correttezza        0.878571\n",
       "Comprensibilità    0.928571\n",
       "Somiglianza        0.967143\n",
       "id                 4.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minerva_data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01f13027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "23089502-08dd-489a-b4a6-b2466d7e247e",
       "rows": [
        [
         "Correttezza",
         "0.8928571428571429"
        ],
        [
         "Comprensibilità",
         "0.942857142857143"
        ],
        [
         "Somiglianza",
         "0.9757142857142859"
        ],
        [
         "id",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "Correttezza        0.892857\n",
       "Comprensibilità    0.942857\n",
       "Somiglianza        0.975714\n",
       "id                 4.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lama_data.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
