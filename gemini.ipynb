{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dabd59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-generativeai\n",
    "# pip install rouge\n",
    "\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31e8a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.environ['GEMINI_KEY'])\n",
    "DIRECTORY_PATH = os.environ['DATA_PATH']\n",
    "GEMINI_VERSION = \"gemini-1.5-flash\"\n",
    "\n",
    "cleaned_fn = \"cleaned.json\"\n",
    "ocred_fn = \"original_ocr.json\"\n",
    "\n",
    "\n",
    "datasetRaw = {}\n",
    "\n",
    "for file_name in [ocred_fn, cleaned_fn]:\n",
    "    if file_name not in os.listdir(DIRECTORY_PATH):\n",
    "        print(f\"ERROR 404 ! File {file_name} not Found...\")\n",
    "\n",
    "    file_path = os.path.join(DIRECTORY_PATH, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        datasetRaw[file_name.split('.')[0]] = json.load(file)\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d44dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_in = datasetRaw['original_ocr']['1']\n",
    "sample_out = datasetRaw['cleaned']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fe8e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = segment_wrapper(sample_in, sample_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5c9199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il punteggio di similarità tra i due testi è un **4**.\n",
      "\n",
      "I testi sono sostanzialmente identici nella trama e nel contenuto.  Il testo \"da valutare\" presenta alcuni errori ortografici e di punteggiatura (es. \"Megnamc\", \"Kon\", \"mastr' Antonio\" invece di \"mastr' Antonio\",  vari problemi di spaziatura e punteggiatura), ma la struttura narrativa e le frasi principali sono le stesse.  La presenza di caratteri strani alla fine del testo \"da valutare\" non influenza la valutazione della similarità del corpo principale della narrazione.  La correzione degli errori grammaticali nel testo \"da valutare\" lo avvicina molto al testo \"di confronto\", rendendoli quasi identici a livello di contenuto.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=GEMINI_VERSION)\n",
    "hypothesis = model.generate_content(prompt).text\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3c0ad",
   "metadata": {},
   "source": [
    "### Output evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11dd40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.environ['OUTPUT_PATH']\n",
    "\n",
    "modes = [\n",
    "    {\n",
    "        \"name\":\"lama\",\n",
    "        \"folder\":\"Llama\"\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"minerva\",\n",
    "        \"folder\":\"Minerva\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc9960e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_wrapper(segment_ocred, segment_clean):\n",
    "    return f\"\"\"\n",
    "        ### Task: Il primo testo è una versione del secondo estratto con oc-Red, ed è stata processata per ridurre gli errori, valuta con un punteggio tra 1 e 5 la somglianza tra le due.\n",
    "        ### Testo da valutare: {segment_ocred}.\n",
    "        ### Testo di confronto: {segment_clean}.\n",
    "        ### Risultato:\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "515a3bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'lama': {'rouge-1': {'r': 0.9018096388956656, 'p': 0.8842998508666347, 'f': 0.8929096945437028}, 'rouge-2': {'r': 0.8611956693983525, 'p': 0.846038729355542, 'f': 0.853540266107022}, 'rouge-l': {'r': 0.9018096388956656, 'p': 0.8842998508666347, 'f': 0.8929096945437028}}, 'minerva': {'rouge-1': {'r': 0.8887436194479311, 'p': 0.8804857763436278, 'f': 0.8840809294354984}, 'rouge-2': {'r': 0.8440152974684236, 'p': 0.8457810368278075, 'f': 0.8442805294840483}, 'rouge-l': {'r': 0.8887436194479311, 'p': 0.8804857763436278, 'f': 0.8840809294354984}}}\n",
      "{'lama': {'rouge-1': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}, 'rouge-2': {'r': 0.8099428484682072, 'p': 0.7656059883750874, 'f': 0.7871362843543889}, 'rouge-l': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}}, 'minerva': {'rouge-1': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}, 'rouge-2': {'r': 0.8099428484682072, 'p': 0.7656059883750874, 'f': 0.7871362843543889}, 'rouge-l': {'r': 0.8662032691596441, 'p': 0.7995476055531758, 'f': 0.8314890987249633}}}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "baseline = {}\n",
    "for mode in modes:\n",
    "    model_scorer = Rouge()\n",
    "    model_outputs = os.path.join(OUTPUT_PATH, mode['folder'])\n",
    "    corrected_chapters = []\n",
    "    baseline_chapters = []\n",
    "    reference_chapters = []\n",
    "    for n, chapter in enumerate(os.listdir(model_outputs)):\n",
    "        complete_chapter = \"\"\n",
    "        with open(os.path.join(model_outputs, chapter), mode='r', encoding='utf-8') as file:\n",
    "            try:\n",
    "                chapter_object = json.load(file)\n",
    "            except Exception as e:\n",
    "                print(e, f\"while trying to read {mode['folder']}-{chapter}\")\n",
    "                continue\n",
    "            for line in chapter_object:\n",
    "                complete_chapter += (\"\\n\"+line['output'])\n",
    "            file.close()\n",
    "        corrected_chapters.append(complete_chapter)\n",
    "        reference_chapters.append(datasetRaw['cleaned'][f'{n+1}'])\n",
    "        baseline_chapters.append(datasetRaw['original_ocr'][f'{n+1}'])\n",
    "    results[mode['name']] = model_scorer.get_scores(corrected_chapters,reference_chapters, avg=True)\n",
    "    baseline[mode['name']] = model_scorer.get_scores(baseline_chapters, reference_chapters, avg=True)\n",
    "print(f\"{'-'*20}\")\n",
    "print(results)\n",
    "print(baseline)\n",
    "print(f\"{'-'*20}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31570ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0be417",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_res = pd.DataFrame(results['lama'])\n",
    "llama_base = pd.DataFrame(baseline['lama'])\n",
    "minerva_res = pd.DataFrame(results['minerva'])\n",
    "minerva_base = pd.DataFrame(baseline['minerva'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28e25a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rouge-1   rouge-2  rouge-l\n",
      "r  0.90181  0.861196  0.90181\n",
      "p  0.88430  0.846039  0.88430\n",
      "f  0.89291  0.853540  0.89291\n",
      "    rouge-1   rouge-2   rouge-l\n",
      "r  0.866203  0.809943  0.866203\n",
      "p  0.799548  0.765606  0.799548\n",
      "f  0.831489  0.787136  0.831489\n",
      "    rouge-1   rouge-2   rouge-l\n",
      "r  0.888744  0.844015  0.888744\n",
      "p  0.880486  0.845781  0.880486\n",
      "f  0.884081  0.844281  0.884081\n",
      "    rouge-1   rouge-2   rouge-l\n",
      "r  0.866203  0.809943  0.866203\n",
      "p  0.799548  0.765606  0.799548\n",
      "f  0.831489  0.787136  0.831489\n"
     ]
    }
   ],
   "source": [
    "print(llama_res)\n",
    "print(llama_base)\n",
    "print(minerva_res)\n",
    "print(minerva_base)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
